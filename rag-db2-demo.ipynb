{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d779f5f-f3b2-4f11-a943-d9232fd4a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db2 Extensions Loaded. Version: 2024-09-16\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "# Text processing\n",
    "import spacy\n",
    "import trafilatura\n",
    "\n",
    "# OpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "# Notebook display utilities\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load Db2 notebook helpers (CONNECT, %sql, etc.)\n",
    "if not os.path.isfile(\"db2.ipynb\"):\n",
    "    os.system(\"wget https://raw.githubusercontent.com/IBM/db2-jupyter/master/db2.ipynb\")\n",
    "\n",
    "%run db2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "254bd58a-b88b-467a-b218-b7f27bd36b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful. test1 @ localhost \n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "# Db2 credentials (used by db2.ipynb's %sql CONNECT CREDENTIALS)\n",
    "db2creds = dotenv_values(\".env\")\n",
    "\n",
    "# Connect to Db2\n",
    "%sql CONNECT CREDENTIALS db2creds\n",
    "\n",
    "# OpenAI setup\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in .env\")\n",
    "\n",
    "EMBED_MODEL = os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "CHAT_MODEL = os.getenv(\"OPENAI_CHAT_MODEL\", \"gpt-4.1-mini\")\n",
    "\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879c8f13-a686-4fd5-adcb-b5d95cf3ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str):\n",
    "    \"\"\"\n",
    "    Generate a vector embedding for the given text using OpenAI.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    resp = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=text\n",
    "    )\n",
    "    return resp.data[0].embedding  # list[float]\n",
    "\n",
    "\n",
    "def chat_with_context(context: str, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Call OpenAI chat model with retrieved context and question.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are a knowledgeable assistant. Answer the question based solely \"\n",
    "        \"on the provided context. If the information is not in the context, \"\n",
    "        \"respond with: 'The information is not available in the provided context.'\"\n",
    "    )\n",
    "\n",
    "    user_msg = f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=512,\n",
    "    )\n",
    "\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897237fa-800a-4284-82b2-014c0283486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn how to put AI to work\n",
      "Become an expert on fundamental and emerging tech topics with our comprehensive guides\n",
      "Reader favorites from the year so far\n",
      "Top analysis of cyber threats\n",
      "Listen to engaging discussions with tech leaders. Watch the latest episodes.\n",
      "AI Academy |\n",
      "Uniting security and governance for the future of AIThis AI Academy episode explores the tug-of-war that risk and assurance leaders experience between governance and security.\n",
      "Explore expert-led sessions on AI agents, data for AI, AI models, AI automation, and AI governance & security\n"
     ]
    }
   ],
   "source": [
    "# Example URL â€“ you can replace this with any article / blog\n",
    "url = \"https://www.ibm.com/blog/ai-and-data\"  # change this if you like\n",
    "\n",
    "downloaded = trafilatura.fetch_url(url)\n",
    "if not downloaded:\n",
    "    raise RuntimeError(f\"Failed to download content from {url}\")\n",
    "\n",
    "text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)\n",
    "if not text:\n",
    "    raise RuntimeError(\"Failed to extract main content from the page\")\n",
    "\n",
    "print(text[:1000])  # peek into first 1000 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da19d462-de6b-4870-abaf-22da4ab42816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'Learn how to put AI to work\\nBecome an expert on fundamental and emerging tech topics with our comprehensive guides\\nReader favorites from the year so far\\nTop analysis of cyber threats\\nListen to engaging discussions with tech leaders. Watch the latest episodes. AI Academy |\\nUniting security and governance for the future of AIThis AI Academy episode explores the tug-of-war that risk and assurance leaders experience between governance and security. Explore expert-led sessions on AI agents, data for ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def chunk_text(text: str, max_tokens: int = 200, overlap: int = 40):\n",
    "    \"\"\"\n",
    "    Very simple sentence-based chunking with overlap.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_len = 0\n",
    "\n",
    "    for sent in sentences:\n",
    "        length = len(sent.split())\n",
    "        if current_len + length > max_tokens and current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            # Overlap\n",
    "            overlap_tokens = \" \".join(\" \".join(current_chunk).split()[-overlap:])\n",
    "            current_chunk = [overlap_tokens, sent]\n",
    "            current_len = len(overlap_tokens.split()) + length\n",
    "        else:\n",
    "            current_chunk.append(sent)\n",
    "            current_len += length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(text, max_tokens=200, overlap=40)\n",
    "len(chunks), chunks[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f9ca60-d204-432b-ac72-7fc4e841e4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n",
      "Command completed.\n"
     ]
    }
   ],
   "source": [
    "# Drop and recreate embeddings table\n",
    "%sql DROP TABLE IF EXISTS embeddings\n",
    "\n",
    "SQL_CREATE_TABLE = \"\"\"\n",
    "CREATE TABLE embeddings (\n",
    "    id INT NOT NULL GENERATED ALWAYS AS IDENTITY (START WITH 1, INCREMENT BY 1),\n",
    "    content CLOB,\n",
    "    embedding VECTOR(1536, FLOAT32),\n",
    "    PRIMARY KEY (id)\n",
    ")\n",
    "\"\"\"\n",
    "%sql {SQL_CREATE_TABLE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98afbaa2-5a8a-4ff5-8f1c-bcbfcf614a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for chunk in chunks:\n",
    "    vec = get_embedding(chunk)\n",
    "    vec_str = \"[\" + \",\".join(str(x) for x in vec) + \"]\"\n",
    "    values.append((chunk, vec_str))\n",
    "\n",
    "# Prepare SQL for inserting\n",
    "stmt = %sql prepare INSERT INTO embeddings (content, embedding) VALUES (?, VECTOR(?, 1536, FLOAT32))\n",
    "\n",
    "# Disable autocommit\n",
    "%sql autocommit off\n",
    "\n",
    "for content, vec_str in values:\n",
    "    %sql execute :stmt using :content, :vec_str\n",
    "\n",
    "%sql commit work\n",
    "%sql autocommit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ddaa645-58c6-4626-af3b-13007b688845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command completed.\n",
      "Command completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CONTEXT</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Learn how to put AI to work\\nBecome an expert ...</td>\n",
       "      <td>0.920621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                            CONTEXT  DISTANCE\n",
       "0   1  Learn how to put AI to work\\nBecome an expert ...  0.920621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# 1) Define the question + embedding\n",
    "# ------------------------------------\n",
    "question = \"What areas of AI and security does this page mention?\"\n",
    "query_vec = get_embedding(question)  # OpenAI embedding for the question\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# 2) Create query_vec table in Db2\n",
    "# ------------------------------------\n",
    "%sql DROP TABLE IF EXISTS query_vec\n",
    "\n",
    "SQL_CREATE_QUERY_VEC = \"\"\"\n",
    "CREATE TABLE query_vec (\n",
    "    id INT,\n",
    "    embedding VECTOR(1536, FLOAT32)\n",
    ")\n",
    "\"\"\"\n",
    "%sql {SQL_CREATE_QUERY_VEC}\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# 3) Insert the query embedding\n",
    "# ------------------------------------\n",
    "query_vec_str = \"[\" + \",\".join(str(x) for x in query_vec) + \"]\"\n",
    "\n",
    "stmt = %sql prepare INSERT INTO query_vec (id, embedding) VALUES (1, VECTOR(?, 1536, FLOAT32))\n",
    "\n",
    "%sql autocommit off\n",
    "%sql execute :stmt using :query_vec_str\n",
    "%sql commit work\n",
    "%sql autocommit on\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# 4) Run vector search (CAST to VARCHAR to avoid CLI0109E)\n",
    "# ------------------------------------\n",
    "top_k = 5\n",
    "\n",
    "SQL_DISTANCE = f\"\"\"\n",
    "SELECT \n",
    "    e.id,\n",
    "    CAST(SUBSTR(e.content, 1, 4000) AS VARCHAR(4000)) AS CONTEXT,\n",
    "    VECTOR_DISTANCE(\n",
    "        e.embedding,\n",
    "        q.embedding,\n",
    "        EUCLIDEAN\n",
    "    ) AS DISTANCE\n",
    "FROM embeddings e, query_vec q\n",
    "ORDER BY DISTANCE ASC\n",
    "FETCH FIRST {top_k} ROWS ONLY\n",
    "\"\"\"\n",
    "\n",
    "result_df = %sql {SQL_DISTANCE}\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1dad9b1-e3d1-406a-ae10-db622241a089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Q:** What areas of AI and security does this page mention?\n",
       "\n",
       "**A:** The page mentions AI agents, data for AI, AI models, AI automation, and AI governance & security as areas of AI and security."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Db2 returns column names in uppercase unless quoted\n",
    "context_column = \"CONTEXT\" if \"CONTEXT\" in result_df.columns else \"context\"\n",
    "\n",
    "# Build a merged context string\n",
    "context_str = \"\\n\\n---\\n\\n\".join(result_df[context_column].tolist())\n",
    "\n",
    "# Ask LLM with context (RAG)\n",
    "answer = chat_with_context(context_str, question)\n",
    "\n",
    "display(Markdown(f\"**Q:** {question}\\n\\n**A:** {answer}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
